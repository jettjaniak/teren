{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device='cuda'\n",
      "Gradients globally enabled: False\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from teren import utils as teren_utils\n",
    "from teren.perturbations import Perturbation\n",
    "\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import plotly_express as px\n",
    "\n",
    "device = teren_utils.get_device_str()\n",
    "\n",
    "print(f\"{device=}\")\n",
    "print(f\"Gradients globally enabled: {torch.is_grad_enabled()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFERENCE_BATCH_SIZE=32\n"
     ]
    }
   ],
   "source": [
    "# each layer is kind of independent experiment, but we save a lot of time by\n",
    "# collecting dataset examples and residual stream activation for many layers at once\n",
    "\n",
    "LAYERS = list(range(model.cfg.n_layers))\n",
    "# LAYERS = 0, 5, 10\n",
    "\n",
    "# pre-trained SAE model availavle in SAELens\n",
    "SAE_RELEASE = \"gpt2-small-res-jb\"\n",
    "\n",
    "# TODO: experiment with hook_resid_post\n",
    "LAYER_TO_SAE_ID = lambda layer: f\"blocks.{layer}.hook_resid_pre\"\n",
    "\n",
    "# HF text  dataset\n",
    "DATASET_PATH = \"NeelNanda/c4-10k\"\n",
    "DATASET_SPLIT = \"train[:1%]\"\n",
    "\n",
    "# how long each tokenized prompt should be\n",
    "CONTEXT_SIZE = 10\n",
    "\n",
    "# how many tokens can be forwarded through the transformer at once\n",
    "# tune to your VRAM, 12_800 works well with 16GB\n",
    "INFERENCE_TOKENS = 320  # 12_800\n",
    "INFERENCE_BATCH_SIZE = INFERENCE_TOKENS // CONTEXT_SIZE\n",
    "print(f\"{INFERENCE_BATCH_SIZE=}\")\n",
    "\n",
    "# what is the minimum activation for a feature to be considered active\n",
    "MIN_FEATURE_ACTIVATION = 0.0\n",
    "# minimum number of tokenized prompts that should have a feature active\n",
    "# for the feature to be included in the experiment\n",
    "MIN_EXAMPLES_PER_FEATURE = 30\n",
    "# ids of feature to consider in the experiment\n",
    "# we can't consider all the features, because of compute & memory constraints\n",
    "CONSIDER_FEATURE_IDS = list(range(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_lens import SAE\n",
    "\n",
    "sae_by_layer = {\n",
    "    # ignore other things it returns\n",
    "    layer: SAE.from_pretrained(\n",
    "        release=SAE_RELEASE,\n",
    "        sae_id=LAYER_TO_SAE_ID(layer),\n",
    "        device=device,\n",
    "    )[0]\n",
    "    for layer in LAYERS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_input_ids (tokenized dataset) shape: (5463, 10)\n"
     ]
    }
   ],
   "source": [
    "all_input_ids = teren_utils.load_and_tokenize_dataset(\n",
    "    path=DATASET_PATH,\n",
    "    split=DATASET_SPLIT,\n",
    "    column_name=\"text\",\n",
    "    tokenizer=model.tokenizer,\n",
    "    max_length=CONTEXT_SIZE,\n",
    ")\n",
    "print(f\"all_input_ids (tokenized dataset) shape: {tuple(all_input_ids.shape)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teren.sae_examples import (\n",
    "    get_sae_feature_examples_by_layer_and_resid_stats_by_layer,\n",
    ")\n",
    "from teren.typing import *\n",
    "\n",
    "consider_feature_ids = [FeatureId(i) for i in range(MIN_EXAMPLES_PER_FEATURE)]\n",
    "\n",
    "examples_by_feature_by_layer, resid_stats_by_layer = (\n",
    "    get_sae_feature_examples_by_layer_and_resid_stats_by_layer(\n",
    "        input_ids=all_input_ids,\n",
    "        model=model,\n",
    "        sae_by_layer=sae_by_layer,\n",
    "        fids=consider_feature_ids,\n",
    "        n_examples=MIN_EXAMPLES_PER_FEATURE,\n",
    "        batch_size=INFERENCE_BATCH_SIZE,\n",
    "        min_activation=MIN_FEATURE_ACTIVATION,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 0\n",
      "Number of selected features: 1\n",
      "Active feature ids: [9]\n",
      "\n",
      "Layer: 1\n",
      "Number of selected features: 1\n",
      "Active feature ids: [11]\n",
      "\n",
      "Layer: 2\n",
      "Number of selected features: 1\n",
      "Active feature ids: [0]\n",
      "\n",
      "Layer: 3\n",
      "Number of selected features: 1\n",
      "Active feature ids: [6]\n",
      "\n",
      "Layer: 4\n",
      "Number of selected features: 5\n",
      "Active feature ids: [7, 8, 12, 15, 19]\n",
      "\n",
      "Layer: 5\n",
      "Number of selected features: 14\n",
      "Active feature ids: [0, 2, 4, 5, 9, 10, 13, 15, 19, 24, 25, 26, 27, 28]\n",
      "\n",
      "Layer: 6\n",
      "Number of selected features: 9\n",
      "Active feature ids: [5, 7, 13, 14, 16, 17, 18, 20, 27]\n",
      "\n",
      "Layer: 7\n",
      "Number of selected features: 12\n",
      "Active feature ids: [0, 5, 6, 10, 14, 15, 17, 18, 20, 21, 26, 29]\n",
      "\n",
      "Layer: 8\n",
      "Number of selected features: 16\n",
      "Active feature ids: [1, 3, 4, 6, 7, 8, 10, 11, 13, 15, 16, 21, 24, 25, 26, 29]\n",
      "\n",
      "Layer: 9\n",
      "Number of selected features: 22\n",
      "Active feature ids: [0, 2, 4, 5, 8, 9, 10, 12, 13, 14, 15, 17, 18, 19, 21, 22, 23, 24, 25, 27, 28, 29]\n",
      "\n",
      "Layer: 10\n",
      "Number of selected features: 13\n",
      "Active feature ids: [0, 1, 2, 7, 13, 15, 17, 20, 22, 25, 26, 27, 28]\n",
      "\n",
      "Layer: 11\n",
      "Number of selected features: 18\n",
      "Active feature ids: [0, 1, 2, 4, 7, 9, 11, 13, 15, 16, 17, 21, 24, 25, 26, 27, 28, 29]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display high-level summary of the data\n",
    "for layer, examples_by_feature in examples_by_feature_by_layer.items():\n",
    "    print(f\"Layer: {layer}\")\n",
    "    active_feature_ids = [f.int for f in examples_by_feature.fids]\n",
    "    print(f\"Number of selected features: {len(active_feature_ids)}\")\n",
    "    print(f\"Active feature ids: {active_feature_ids}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 0\n",
      "input_ids shape: (1, 30, 10) (n_features, n_examples, context_size)\n",
      "resid_acts shape: (1, 30, 10, 768) (n_features, n_examples, context_size, d_model)\n",
      "clean_loss shape: (1, 30, 9) (n_features, n_examples, context_size - 1)\n"
     ]
    }
   ],
   "source": [
    "def print_examples_shapes(idx):\n",
    "    print(f\"Layer: {LAYERS[idx]}\")\n",
    "    examples_by_feature = examples_by_feature_by_layer[idx]\n",
    "    print(\n",
    "        f\"input_ids shape: {tuple(examples_by_feature.input_ids.shape)} (n_features, n_examples, context_size)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"resid_acts shape: {tuple(examples_by_feature.resid_acts.shape)} (n_features, n_examples, context_size, d_model)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"clean_loss shape: {tuple(examples_by_feature.clean_loss.shape)} (n_features, n_examples, context_size - 1)\"\n",
    "    )\n",
    "\n",
    "\n",
    "print_examples_shapes(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_positive_definite(A):\n",
    "    try:\n",
    "        torch.linalg.cholesky(A)\n",
    "        return True\n",
    "    except RuntimeError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resid_stats_by_layer[0].cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualenvs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
